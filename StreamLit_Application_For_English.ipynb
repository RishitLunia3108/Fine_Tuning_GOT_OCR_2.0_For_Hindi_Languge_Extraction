{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YQ33d93XOFjw"
      },
      "outputs": [],
      "source": [
        "! pip install -q streamlit tiktoken verovio transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcU7G5PJOZY2",
        "outputId": "f1747cc5-066b-4837-d40a-f5f82a18e586"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing app1.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app1.py\n",
        "\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "import io\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import tempfile\n",
        "\n",
        "# Function to load model and tokenizer\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    tokenizer = AutoTokenizer.from_pretrained('ucaslcl/GOT-OCR2_0', trust_remote_code=True)\n",
        "    model = AutoModel.from_pretrained('ucaslcl/GOT-OCR2_0', trust_remote_code=True, low_cpu_mem_usage=True, device_map='cuda', use_safetensors=True, pad_token_id=tokenizer.eos_token_id)\n",
        "    model = model.eval().cuda()\n",
        "    return tokenizer, model\n",
        "\n",
        "# Main Streamlit app\n",
        "def main():\n",
        "    st.title(\"OCR Application\")\n",
        "\n",
        "    # Load model and tokenizer\n",
        "    tokenizer, model = load_model()\n",
        "\n",
        "    # File uploader\n",
        "    uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        # Display the uploaded image\n",
        "        image = Image.open(uploaded_file)\n",
        "        st.image(image, caption='Uploaded Image', use_column_width=True)\n",
        "\n",
        "        # Perform OCR when button is clicked\n",
        "        if st.button('Extract Text'):\n",
        "            # Save the uploaded file to a temporary file\n",
        "            with tempfile.NamedTemporaryFile(delete=False, suffix='.png') as temp_file:\n",
        "                temp_filename = temp_file.name\n",
        "                image.save(temp_filename, format='PNG')\n",
        "\n",
        "            # Perform OCR\n",
        "            with st.spinner('Extracting text...'):\n",
        "                res = model.chat(tokenizer, temp_filename, ocr_type='ocr')\n",
        "\n",
        "            # Display result\n",
        "            st.subheader(\"Extracted Text:\")\n",
        "            st.write(res)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkJrld7IOeb3",
        "outputId": "12ca98e3-6f8f-4ed0-d8ca-f0ba11559fe1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34.16.151.148\n"
          ]
        }
      ],
      "source": [
        "! wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1IgDnbSQs9a",
        "outputId": "97c7eeaa-de9e-46a4-9053-8bdae04cc55e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.16.151.148:8501\u001b[0m\n",
            "\u001b[0m\n",
            "your url is: https://polite-lizards-yawn.loca.lt\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app1.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
