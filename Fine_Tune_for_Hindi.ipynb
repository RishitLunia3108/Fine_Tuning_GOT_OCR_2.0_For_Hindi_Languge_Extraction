{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-09-30T05:52:07.845640Z","iopub.status.busy":"2024-09-30T05:52:07.845128Z","iopub.status.idle":"2024-09-30T05:52:09.908949Z","shell.execute_reply":"2024-09-30T05:52:09.907779Z","shell.execute_reply.started":"2024-09-30T05:52:07.845604Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working\n",".:\n"]}],"source":["!pwd\n","!ls -R"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-09-30T05:52:14.956238Z","iopub.status.busy":"2024-09-30T05:52:14.955669Z","iopub.status.idle":"2024-09-30T05:52:19.002580Z","shell.execute_reply":"2024-09-30T05:52:19.001411Z","shell.execute_reply.started":"2024-09-30T05:52:14.956185Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'ms-swift'...\n","remote: Enumerating objects: 22220, done.\u001b[K\n","remote: Counting objects: 100% (1827/1827), done.\u001b[K\n","remote: Compressing objects: 100% (738/738), done.\u001b[K\n","remote: Total 22220 (delta 1333), reused 1492 (delta 1053), pack-reused 20393 (from 1)\u001b[K\n","Receiving objects: 100% (22220/22220), 49.23 MiB | 40.17 MiB/s, done.\n","Resolving deltas: 100% (15890/15890), done.\n","/kaggle/working/ms-swift\n"]}],"source":["!git clone https://github.com/modelscope/ms-swift.git\n","%cd ms-swift"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-30T05:52:30.161805Z","iopub.status.busy":"2024-09-30T05:52:30.160893Z","iopub.status.idle":"2024-09-30T05:53:28.491073Z","shell.execute_reply":"2024-09-30T05:53:28.489967Z","shell.execute_reply.started":"2024-09-30T05:52:30.161765Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Obtaining file:///kaggle/working/ms-swift\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from ms-swift==2.5.0.dev0) (0.34.2)\n","Collecting addict (from ms-swift==2.5.0.dev0)\n","  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from ms-swift==2.5.0.dev0) (3.9.5)\n","Collecting attrdict (from ms-swift==2.5.0.dev0)\n","  Downloading attrdict-2.0.1-py2.py3-none-any.whl.metadata (6.7 kB)\n","Collecting binpacking (from ms-swift==2.5.0.dev0)\n","  Downloading binpacking-1.5.2.tar.gz (8.7 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: dacite in /opt/conda/lib/python3.10/site-packages (from ms-swift==2.5.0.dev0) (1.8.1)\n","Collecting datasets<3.0 (from ms-swift==2.5.0.dev0)\n","  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n","Collecting einops (from ms-swift==2.5.0.dev0)\n","  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: importlib_metadata in /opt/conda/lib/python3.10/site-packages (from ms-swift==2.5.0.dev0) (7.0.0)\n","Requirement already satisfied: jieba in /opt/conda/lib/python3.10/site-packages (from ms-swift==2.5.0.dev0) (0.42.1)\n","Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from ms-swift==2.5.0.dev0) (3.7.5)\n","Collecting modelscope<1.19,>=1.17 (from modelscope[datasets]<1.19,>=1.17->ms-swift==2.5.0.dev0)\n","  Downloading modelscope-1.18.1-py3-none-any.whl.metadata (40 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from ms-swift==2.5.0.dev0) (3.2.4)\n","Requirement already satisfied: numpy<2.0 in /opt/conda/lib/python3.10/site-packages (from ms-swift==2.5.0.dev0) (1.26.4)\n","Collecting oss2 (from ms-swift==2.5.0.dev0)\n","  Downloading oss2-2.19.0.tar.gz (298 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.1/298.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from ms-swift==2.5.0.dev0) (2.2.2)\n","Collecting peft<0.13.0,>=0.11.0 (from ms-swift==2.5.0.dev0)\n","  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from ms-swift==2.5.0.dev0) (2.32.3)\n","Collecting rouge (from ms-swift==2.5.0.dev0)\n","  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n","Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from ms-swift==2.5.0.dev0) (0.4.5)\n","Requirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (from ms-swift==2.5.0.dev0) (2.16.2)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from ms-swift==2.5.0.dev0) (4.66.4)\n","Requirement already satisfied: transformers<4.47,>=4.33 in /opt/conda/lib/python3.10/site-packages (from ms-swift==2.5.0.dev0) (4.44.2)\n","Collecting transformers_stream_generator (from ms-swift==2.5.0.dev0)\n","  Downloading transformers-stream-generator-0.0.5.tar.gz (13 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting trl>=0.10.1 (from ms-swift==2.5.0.dev0)\n","  Downloading trl-0.11.1-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: charset_normalizer in /opt/conda/lib/python3.10/site-packages (from ms-swift==2.5.0.dev0) (3.3.2)\n","Collecting cpm_kernels (from ms-swift==2.5.0.dev0)\n","  Downloading cpm_kernels-1.0.11-py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from ms-swift==2.5.0.dev0) (0.111.0)\n","Collecting gradio>=3.40.0 (from ms-swift==2.5.0.dev0)\n","  Downloading gradio-4.44.0-py3-none-any.whl.metadata (15 kB)\n","Collecting openai (from ms-swift==2.5.0.dev0)\n","  Downloading openai-1.50.2-py3-none-any.whl.metadata (24 kB)\n","Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from ms-swift==2.5.0.dev0) (0.2.0)\n","Collecting tiktoken (from ms-swift==2.5.0.dev0)\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: uvicorn in /opt/conda/lib/python3.10/site-packages (from ms-swift==2.5.0.dev0) (0.30.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets<3.0->ms-swift==2.5.0.dev0) (3.15.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets<3.0->ms-swift==2.5.0.dev0) (16.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets<3.0->ms-swift==2.5.0.dev0) (0.3.8)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets<3.0->ms-swift==2.5.0.dev0) (3.4.1)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets<3.0->ms-swift==2.5.0.dev0) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets<3.0->ms-swift==2.5.0.dev0) (2024.6.1)\n","Requirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets<3.0->ms-swift==2.5.0.dev0) (0.25.0)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets<3.0->ms-swift==2.5.0.dev0) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets<3.0->ms-swift==2.5.0.dev0) (6.0.2)\n","Requirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=3.40.0->ms-swift==2.5.0.dev0) (22.1.0)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=3.40.0->ms-swift==2.5.0.dev0) (4.4.0)\n","Collecting ffmpy (from gradio>=3.40.0->ms-swift==2.5.0.dev0)\n","  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n","Collecting gradio-client==1.3.0 (from gradio>=3.40.0->ms-swift==2.5.0.dev0)\n","  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: httpx>=0.24.1 in /opt/conda/lib/python3.10/site-packages (from gradio>=3.40.0->ms-swift==2.5.0.dev0) (0.27.0)\n","Requirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/conda/lib/python3.10/site-packages (from gradio>=3.40.0->ms-swift==2.5.0.dev0) (6.4.0)\n","Requirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=3.40.0->ms-swift==2.5.0.dev0) (3.1.4)\n","Requirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=3.40.0->ms-swift==2.5.0.dev0) (2.1.5)\n","Requirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=3.40.0->ms-swift==2.5.0.dev0) (3.10.4)\n","Requirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=3.40.0->ms-swift==2.5.0.dev0) (10.3.0)\n","Requirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=3.40.0->ms-swift==2.5.0.dev0) (2.9.2)\n","Requirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio>=3.40.0->ms-swift==2.5.0.dev0) (0.25.1)\n","Requirement already satisfied: python-multipart>=0.0.9 in /opt/conda/lib/python3.10/site-packages (from gradio>=3.40.0->ms-swift==2.5.0.dev0) (0.0.9)\n","Collecting ruff>=0.2.2 (from gradio>=3.40.0->ms-swift==2.5.0.dev0)\n","  Downloading ruff-0.6.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n","Collecting semantic-version~=2.0 (from gradio>=3.40.0->ms-swift==2.5.0.dev0)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting tomlkit==0.12.0 (from gradio>=3.40.0->ms-swift==2.5.0.dev0)\n","  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: typer<1.0,>=0.12 in /opt/conda/lib/python3.10/site-packages (from gradio>=3.40.0->ms-swift==2.5.0.dev0) (0.12.3)\n","Requirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gradio>=3.40.0->ms-swift==2.5.0.dev0) (4.12.2)\n","Collecting urllib3~=2.0 (from gradio>=3.40.0->ms-swift==2.5.0.dev0)\n","  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n","Requirement already satisfied: websockets<13.0,>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio-client==1.3.0->gradio>=3.40.0->ms-swift==2.5.0.dev0) (12.0)\n","Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /opt/conda/lib/python3.10/site-packages (from fastapi->ms-swift==2.5.0.dev0) (0.37.2)\n","Requirement already satisfied: fastapi-cli>=0.0.2 in /opt/conda/lib/python3.10/site-packages (from fastapi->ms-swift==2.5.0.dev0) (0.0.4)\n","Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from fastapi->ms-swift==2.5.0.dev0) (5.10.0)\n","Requirement already satisfied: email_validator>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from fastapi->ms-swift==2.5.0.dev0) (2.1.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->ms-swift==2.5.0.dev0) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->ms-swift==2.5.0.dev0) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->ms-swift==2.5.0.dev0) (4.53.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->ms-swift==2.5.0.dev0) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->ms-swift==2.5.0.dev0) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->ms-swift==2.5.0.dev0) (2.9.0.post0)\n","Requirement already satisfied: attrs in /opt/conda/lib/python3.10/site-packages (from modelscope[datasets]<1.19,>=1.17->ms-swift==2.5.0.dev0) (23.2.0)\n","Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from modelscope[datasets]<1.19,>=1.17->ms-swift==2.5.0.dev0) (1.14.1)\n","Collecting setuptools==69.5.1 (from modelscope[datasets]<1.19,>=1.17->ms-swift==2.5.0.dev0)\n","  Downloading setuptools-69.5.1-py3-none-any.whl.metadata (6.2 kB)\n","Collecting simplejson>=3.3.0 (from modelscope[datasets]<1.19,>=1.17->ms-swift==2.5.0.dev0)\n","  Downloading simplejson-3.19.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n","Requirement already satisfied: sortedcontainers>=1.5.9 in /opt/conda/lib/python3.10/site-packages (from modelscope[datasets]<1.19,>=1.17->ms-swift==2.5.0.dev0) (2.4.0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->ms-swift==2.5.0.dev0) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->ms-swift==2.5.0.dev0) (2024.1)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft<0.13.0,>=0.11.0->ms-swift==2.5.0.dev0) (5.9.3)\n","Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft<0.13.0,>=0.11.0->ms-swift==2.5.0.dev0) (2.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->ms-swift==2.5.0.dev0) (3.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->ms-swift==2.5.0.dev0) (2024.8.30)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<4.47,>=4.33->ms-swift==2.5.0.dev0) (2024.5.15)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<4.47,>=4.33->ms-swift==2.5.0.dev0) (0.19.1)\n","Collecting tyro>=0.5.11 (from trl>=0.10.1->ms-swift==2.5.0.dev0)\n","  Downloading tyro-0.8.11-py3-none-any.whl.metadata (8.4 kB)\n","Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn->ms-swift==2.5.0.dev0) (8.1.7)\n","Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn->ms-swift==2.5.0.dev0) (0.14.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->ms-swift==2.5.0.dev0) (1.3.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->ms-swift==2.5.0.dev0) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->ms-swift==2.5.0.dev0) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->ms-swift==2.5.0.dev0) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->ms-swift==2.5.0.dev0) (4.0.3)\n","Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from attrdict->ms-swift==2.5.0.dev0) (1.16.0)\n","Requirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from binpacking->ms-swift==2.5.0.dev0) (1.0.0)\n","Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib_metadata->ms-swift==2.5.0.dev0) (3.19.2)\n","Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai->ms-swift==2.5.0.dev0) (1.9.0)\n","Collecting jiter<1,>=0.4.0 (from openai->ms-swift==2.5.0.dev0)\n","  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai->ms-swift==2.5.0.dev0) (1.3.1)\n","Requirement already satisfied: crcmod>=1.7 in /opt/conda/lib/python3.10/site-packages (from oss2->ms-swift==2.5.0.dev0) (1.7)\n","Requirement already satisfied: pycryptodome>=3.4.7 in /opt/conda/lib/python3.10/site-packages (from oss2->ms-swift==2.5.0.dev0) (3.20.0)\n","Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2->ms-swift==2.5.0.dev0)\n","  Downloading aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl.metadata (1.5 kB)\n","Collecting aliyun-python-sdk-core>=2.13.12 (from oss2->ms-swift==2.5.0.dev0)\n","  Downloading aliyun-python-sdk-core-2.15.2.tar.gz (449 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.5/449.5 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard->ms-swift==2.5.0.dev0) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard->ms-swift==2.5.0.dev0) (1.62.2)\n","Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard->ms-swift==2.5.0.dev0) (3.6)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard->ms-swift==2.5.0.dev0) (3.20.3)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->ms-swift==2.5.0.dev0) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard->ms-swift==2.5.0.dev0) (3.0.4)\n","Collecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2->ms-swift==2.5.0.dev0)\n","  Downloading jmespath-0.10.0-py2.py3-none-any.whl.metadata (8.0 kB)\n","Requirement already satisfied: cryptography>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2->ms-swift==2.5.0.dev0) (42.0.8)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio>=3.40.0->ms-swift==2.5.0.dev0) (1.2.0)\n","Requirement already satisfied: dnspython>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from email_validator>=2.0.0->fastapi->ms-swift==2.5.0.dev0) (2.6.1)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio>=3.40.0->ms-swift==2.5.0.dev0) (1.0.5)\n","Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio>=3.40.0->ms-swift==2.5.0.dev0) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio>=3.40.0->ms-swift==2.5.0.dev0) (2.23.4)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft<0.13.0,>=0.11.0->ms-swift==2.5.0.dev0) (1.13.3)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft<0.13.0,>=0.11.0->ms-swift==2.5.0.dev0) (3.3)\n","Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio>=3.40.0->ms-swift==2.5.0.dev0) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio>=3.40.0->ms-swift==2.5.0.dev0) (13.7.1)\n","Requirement already satisfied: docstring-parser>=0.16 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl>=0.10.1->ms-swift==2.5.0.dev0) (0.16)\n","Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl>=0.10.1->ms-swift==2.5.0.dev0)\n","  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi->ms-swift==2.5.0.dev0) (0.6.1)\n","Requirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi->ms-swift==2.5.0.dev0) (1.0.1)\n","Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi->ms-swift==2.5.0.dev0) (0.19.0)\n","Requirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0->fastapi->ms-swift==2.5.0.dev0) (0.22.0)\n","Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=3.0.0->aliyun-python-sdk-core>=2.13.12->oss2->ms-swift==2.5.0.dev0) (1.16.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=3.40.0->ms-swift==2.5.0.dev0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=3.40.0->ms-swift==2.5.0.dev0) (2.18.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft<0.13.0,>=0.11.0->ms-swift==2.5.0.dev0) (1.3.0)\n","Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=3.0.0->aliyun-python-sdk-core>=2.13.12->oss2->ms-swift==2.5.0.dev0) (2.22)\n","Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=3.40.0->ms-swift==2.5.0.dev0) (0.1.2)\n","Downloading datasets-2.21.0-py3-none-any.whl (527 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gradio-4.44.0-py3-none-any.whl (18.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n","Downloading modelscope-1.18.1-py3-none-any.whl (5.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading setuptools-69.5.1-py3-none-any.whl (894 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m894.6/894.6 kB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trl-0.11.1-py3-none-any.whl (318 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.4/318.4 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n","Downloading cpm_kernels-1.0.11-py3-none-any.whl (416 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.6/416.6 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading openai-1.50.2-py3-none-any.whl (382 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.0/383.0 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading rouge-1.0.1-py3-none-any.whl (13 kB)\n","Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl (99 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.5/99.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ruff-0.6.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n","\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Downloading simplejson-3.19.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tyro-0.8.11-py3-none-any.whl (105 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.9/105.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.3/126.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n","Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n","Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n","Building wheels for collected packages: binpacking, oss2, transformers_stream_generator, aliyun-python-sdk-core\n","  Building wheel for binpacking (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for binpacking: filename=binpacking-1.5.2-py3-none-any.whl size=10093 sha256=fae3a4091af94af86856c9c36e17d3e4f327ad325f32eb1f82cc66b47c0c407b\n","  Stored in directory: /root/.cache/pip/wheels/4f/09/07/93d7c3a8acc3f39fc972dd12b8b8131fdd00f9e61ca09ed723\n","  Building wheel for oss2 (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for oss2: filename=oss2-2.19.0-py3-none-any.whl size=123845 sha256=086fea2ccb115a0b3bd5aa59ef6051b60bdb5fc9207d1e5215d5bae41a0d1e6c\n","  Stored in directory: /root/.cache/pip/wheels/f5/a7/91/72a8bf5c60230015484cdc3e5d24635ecea87faea8908b75ec\n","  Building wheel for transformers_stream_generator (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for transformers_stream_generator: filename=transformers_stream_generator-0.0.5-py3-none-any.whl size=12425 sha256=a9cc1d1498e2144bf42003fcf5032533711012d68a1b89247fa7b1ce784094a5\n","  Stored in directory: /root/.cache/pip/wheels/95/4a/90/140f7b67d125906f6a165f38aad212ecb4a695ad0d87582437\n","  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.15.2-py3-none-any.whl size=535313 sha256=3df593a956d8f4e9a7498a99fce990bbe9a29c780877c7cb76888714322ab0c3\n","  Stored in directory: /root/.cache/pip/wheels/96/64/cd/d4ec2561e5a29e5272b8e776afb164d339b2fd0d0b616a5bcf\n","Successfully built binpacking oss2 transformers_stream_generator aliyun-python-sdk-core\n","Installing collected packages: cpm_kernels, addict, urllib3, tomlkit, simplejson, shtab, setuptools, semantic-version, ruff, rouge, jmespath, jiter, ffmpy, einops, binpacking, attrdict, tyro, tiktoken, openai, modelscope, aliyun-python-sdk-core, gradio-client, datasets, aliyun-python-sdk-kms, oss2, trl, transformers_stream_generator, peft, gradio, ms-swift\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.26.18\n","    Uninstalling urllib3-1.26.18:\n","      Successfully uninstalled urllib3-1.26.18\n","  Attempting uninstall: tomlkit\n","    Found existing installation: tomlkit 0.13.2\n","    Uninstalling tomlkit-0.13.2:\n","      Successfully uninstalled tomlkit-0.13.2\n","  Attempting uninstall: setuptools\n","    Found existing installation: setuptools 70.0.0\n","    Uninstalling setuptools-70.0.0:\n","      Successfully uninstalled setuptools-70.0.0\n","  Attempting uninstall: jmespath\n","    Found existing installation: jmespath 1.0.1\n","    Uninstalling jmespath-1.0.1:\n","      Successfully uninstalled jmespath-1.0.1\n","  Attempting uninstall: datasets\n","    Found existing installation: datasets 3.0.0\n","    Uninstalling datasets-3.0.0:\n","      Successfully uninstalled datasets-3.0.0\n","  Running setup.py develop for ms-swift\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","boto3 1.26.100 requires botocore<1.30.0,>=1.29.100, but you have botocore 1.35.16 which is incompatible.\n","conda 24.7.1 requires packaging>=23.0, but you have packaging 21.3 which is incompatible.\n","distributed 2024.7.1 requires dask==2024.7.1, but you have dask 2024.9.0 which is incompatible.\n","jupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","kfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\n","kfp 2.5.0 requires urllib3<2.0.0, but you have urllib3 2.2.3 which is incompatible.\n","rapids-dask-dependency 24.8.0a0 requires dask==2024.7.1, but you have dask 2024.9.0 which is incompatible.\n","ydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed addict-2.4.0 aliyun-python-sdk-core-2.15.2 aliyun-python-sdk-kms-2.16.5 attrdict-2.0.1 binpacking-1.5.2 cpm_kernels-1.0.11 datasets-2.21.0 einops-0.8.0 ffmpy-0.4.0 gradio-4.44.0 gradio-client-1.3.0 jiter-0.5.0 jmespath-0.10.0 modelscope-1.18.1 ms-swift-2.5.0.dev0 openai-1.50.2 oss2-2.19.0 peft-0.12.0 rouge-1.0.1 ruff-0.6.8 semantic-version-2.10.0 setuptools-69.5.1 shtab-1.7.1 simplejson-3.19.3 tiktoken-0.7.0 tomlkit-0.12.0 transformers_stream_generator-0.0.5 trl-0.11.1 tyro-0.8.11 urllib3-2.2.1\n"]}],"source":["!pip install -e .[llm]"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-09-30T05:54:01.116999Z","iopub.status.busy":"2024-09-30T05:54:01.116079Z","iopub.status.idle":"2024-09-30T05:54:01.123333Z","shell.execute_reply":"2024-09-30T05:54:01.122305Z","shell.execute_reply.started":"2024-09-30T05:54:01.116956Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/working\n"]}],"source":["%cd .."]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-09-30T05:54:04.126494Z","iopub.status.busy":"2024-09-30T05:54:04.125856Z","iopub.status.idle":"2024-09-30T05:54:04.130770Z","shell.execute_reply":"2024-09-30T05:54:04.129889Z","shell.execute_reply.started":"2024-09-30T05:54:04.126453Z"},"trusted":true},"outputs":[],"source":["import os\n","\n","# Set environment variables\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Kaggle typically provides a single GPU\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-09-30T05:54:06.735276Z","iopub.status.busy":"2024-09-30T05:54:06.734837Z","iopub.status.idle":"2024-09-30T05:54:20.528869Z","shell.execute_reply":"2024-09-30T05:54:20.527739Z","shell.execute_reply.started":"2024-09-30T05:54:06.735228Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting verovio\n","  Downloading verovio-4.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n","Downloading verovio-4.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: verovio\n","Successfully installed verovio-4.3.1\n"]}],"source":["! pip install verovio"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-09-30T05:54:26.300301Z","iopub.status.busy":"2024-09-30T05:54:26.299905Z","iopub.status.idle":"2024-09-30T05:54:26.532952Z","shell.execute_reply":"2024-09-30T05:54:26.532184Z","shell.execute_reply.started":"2024-09-30T05:54:26.300265Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import json\n","\n","# Load the CSV data\n","file_path = '/kaggle/input/hindi-ocr-synthetic-line-image-text-pair/data_80k/data.csv'\n","df = pd.read_csv(file_path, encoding='utf-8')\n"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-09-30T05:54:29.300723Z","iopub.status.busy":"2024-09-30T05:54:29.300355Z","iopub.status.idle":"2024-09-30T05:54:35.365426Z","shell.execute_reply":"2024-09-30T05:54:35.364509Z","shell.execute_reply.started":"2024-09-30T05:54:29.300687Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["JSON file created successfully!\n"]}],"source":["import os\n","import json\n","\n","# Base path for images\n","image_base_path = '/kaggle/input/hindi-ocr-synthetic-line-image-text-pair/data_80k/output_images/'\n","\n","json_data = []\n","\n","# Loop through the CSV data and create JSON objects\n","for index, row in df.iterrows():\n","    # Construct the full image path by combining the base path with the filename\n","    full_image_path = os.path.join(image_base_path, row['image_file'])\n","    \n","    json_obj = {\n","        \"query\": \"<image>Transcribe the text in this image\",  # Fixed query text\n","        \"response\": row['text'],                             # Expected output from the CSV\n","        \"images\": [full_image_path]                          # Full image path\n","    }\n","    json_data.append(json_obj)\n","\n","# Convert the list of dictionaries to JSON format\n","json_output = json.dumps(json_data, indent=4, ensure_ascii=False)\n","\n","# Save to a JSON file (optional)\n","output_file_path = '/kaggle/working/output_data.json'\n","with open(output_file_path, 'w', encoding='utf-8') as f:\n","    f.write(json_output)\n","\n","print(\"JSON file created successfully!\")\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-09-30T09:39:27.938112Z","iopub.status.busy":"2024-09-30T09:39:27.937737Z","iopub.status.idle":"2024-09-30T09:39:28.985676Z","shell.execute_reply":"2024-09-30T09:39:28.984460Z","shell.execute_reply.started":"2024-09-30T09:39:27.938076Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/bin/bash: line 1: swift: command not found\n"]}],"source":["!swift sft \\\n","--model_type got-ocr2 \\\n","--model_id_or_path stepfun-ai/GOT-OCR2_0 \\\n","--sft_type lora \\\n","--dataset /kaggle/working/output_data.json \\\n","--output_dir /kaggle/working/hindi_got_model_3 \\\n","--num_train_epochs 1 \\\n","--max_steps 1000 \\\n","--per_device_train_batch_size 1 \\\n","--gradient_accumulation_steps 4 \\\n","--learning_rate 2e-5 \\\n","--lora_rank 8 \\\n","--lora_alpha 32 \\\n","--lora_dropout 0.05 \\\n","--evaluation_strategy steps \\\n","--eval_steps 200 \\\n","--save_strategy steps \\\n","--save_steps 200"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-09-30T09:32:45.067032Z","iopub.status.busy":"2024-09-30T09:32:45.066705Z","iopub.status.idle":"2024-09-30T09:32:45.411064Z","shell.execute_reply":"2024-09-30T09:32:45.409792Z","shell.execute_reply.started":"2024-09-30T09:32:45.066996Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'df' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m json_data \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Loop through the CSV data and create JSON objects (limit to 10 files)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m:\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Stop after processing 10 files\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"]}],"source":["import os\n","import json\n","\n","# Base path for images\n","image_base_path = '/kaggle/input/hindi-ocr-synthetic-line-image-text-pair/data_80k/TestSamples/'\n","\n","json_data = []\n","\n","# Loop through the CSV data and create JSON objects (limit to 10 files)\n","for index, row in df.iterrows():\n","    if index >= 10:\n","        break  # Stop after processing 10 files\n","    \n","    # Construct the full image path by combining the base path with the filename\n","    full_image_path = os.path.join(image_base_path, row['image_file'])\n","    \n","    json_obj = {\n","        \"query\": \"<image>Transcribe the text in this image\",  # Fixed query text\n","        \"response\": row['text'],                             # Expected output from the CSV\n","        \"images\": [full_image_path]                          # Full image path\n","    }\n","    json_data.append(json_obj)\n","\n","# Convert the list of dictionaries to JSON format\n","json_output = json.dumps(json_data, indent=4, ensure_ascii=False)\n","\n","# Save to a JSON file (optional)\n","output_file_path = '/kaggle/working/test1.json'\n","with open(output_file_path, 'w', encoding='utf-8') as f:\n","    f.write(json_output)\n","\n","print(\"JSON file created successfully!\")\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-09-30T08:18:48.219108Z","iopub.status.busy":"2024-09-30T08:18:48.218117Z","iopub.status.idle":"2024-09-30T08:19:16.803601Z","shell.execute_reply":"2024-09-30T08:19:16.802411Z","shell.execute_reply.started":"2024-09-30T08:18:48.219063Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["run sh: `/opt/conda/bin/python3.10 /kaggle/working/ms-swift/swift/cli/infer.py --ckpt_dir /kaggle/working/hindi_got_model_3/got-ocr2/v0-20240930-060444/checkpoint-1000 --dataset /kaggle/working/test1.json --load_dataset_config true`\n","[INFO:swift] Successfully registered `/kaggle/working/ms-swift/swift/llm/data/dataset_info.json`\n","[INFO:swift] No vLLM installed, if you are using vLLM, you will get `ImportError: cannot import name 'get_vllm_engine' from 'swift.llm'`\n","[INFO:swift] No LMDeploy installed, if you are using LMDeploy, you will get `ImportError: cannot import name 'prepare_lmdeploy_engine_template' from 'swift.llm'`\n","[INFO:swift] Start time of running main: 2024-09-30 08:19:06.220834\n","[INFO:swift] ckpt_dir: /kaggle/working/hindi_got_model_3/got-ocr2/v0-20240930-060444/checkpoint-1000\n","[INFO:swift] Setting model_info['revision']: master\n","[INFO:swift] Setting args.eval_human: False\n","[INFO:swift] args: InferArguments(model_type='got-ocr2', model_id_or_path='stepfun-ai/GOT-OCR2_0', model_revision='master', sft_type='lora', template_type='got_ocr2', infer_backend='pt', ckpt_dir='/kaggle/working/hindi_got_model_3/got-ocr2/v0-20240930-060444/checkpoint-1000', result_dir=None, load_args_from_ckpt_dir=True, load_dataset_config=True, eval_human=False, seed=42, dtype='bf16', model_kwargs={}, dataset=['/kaggle/working/test1.json'], val_dataset=[], dataset_seed=42, dataset_test_ratio=0.01, show_dataset_sample=-1, save_result=True, system='        You should follow the instructions carefully and explain your answers in detail.', tools_prompt='react_en', max_length=None, truncation_strategy='delete', check_dataset_strategy='none', model_name=[None, None], model_author=[None, None], quant_method=None, quantization_bit=0, hqq_axis=0, hqq_dynamic_config_path=None, bnb_4bit_comp_dtype='bf16', bnb_4bit_quant_type='nf4', bnb_4bit_use_double_quant=True, bnb_4bit_quant_storage=None, max_new_tokens=2048, do_sample=None, temperature=None, top_k=None, top_p=None, repetition_penalty=None, num_beams=1, stop_words=[], rope_scaling=None, use_flash_attn=None, ignore_args_error=False, stream=True, merge_lora=False, merge_device_map='cpu', save_safetensors=True, overwrite_generation_config=False, verbose=None, local_repo_path=None, custom_register_path=None, custom_dataset_info=None, device_map_config=None, device_max_memory=[], hub_token=None, gpu_memory_utilization=0.9, tensor_parallel_size=1, max_num_seqs=256, max_model_len=None, disable_custom_all_reduce=True, enforce_eager=False, limit_mm_per_prompt=None, vllm_enable_lora=False, vllm_max_lora_rank=16, lora_modules=[], max_logprobs=20, tp=1, cache_max_entry_count=0.8, quant_policy=0, vision_batch_size=1, self_cognition_sample=0, train_dataset_sample=-1, val_dataset_sample=None, safe_serialization=None, model_cache_dir=None, merge_lora_and_save=None, custom_train_dataset_path=[], custom_val_dataset_path=[], vllm_lora_modules=None, device_map_config_path=None)\n","[INFO:swift] Global seed set to 42\n","device_count: 1\n","[INFO:swift] Downloading the model from ModelScope Hub, model_id: stepfun-ai/GOT-OCR2_0\n","[WARNING:modelscope] Using branch: master as version is unstable, use with caution\n","[INFO:swift] Loading the model using model_dir: /root/.cache/modelscope/hub/stepfun-ai/GOT-OCR2_0\n","[INFO:swift] model_kwargs: {'device_map': 'cuda:0'}\n","[INFO:swift] model.max_model_len: 32768\n","[INFO:swift] model_config: GOTConfig {\n","  \"_name_or_path\": \"/root/.cache/modelscope/hub/stepfun-ai/GOT-OCR2_0\",\n","  \"architectures\": [\n","    \"GOTQwenForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"auto_map\": {\n","    \"AutoConfig\": \"modeling_GOT.GOTConfig\",\n","    \"AutoModel\": \"modeling_GOT.GOTQwenForCausalLM\"\n","  },\n","  \"bos_token_id\": 151643,\n","  \"eos_token_id\": 151643,\n","  \"freeze_vision_tower\": false,\n","  \"hidden_act\": \"silu\",\n","  \"hidden_size\": 1024,\n","  \"im_end_token\": 151858,\n","  \"im_patch_token\": 151859,\n","  \"im_start_token\": 151857,\n","  \"image_token_len\": 256,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 2816,\n","  \"max_position_embeddings\": 32768,\n","  \"max_window_layers\": 21,\n","  \"model_type\": \"GOT\",\n","  \"num_attention_heads\": 16,\n","  \"num_hidden_layers\": 24,\n","  \"num_key_value_heads\": 16,\n","  \"rms_norm_eps\": 1e-06,\n","  \"rope_theta\": 1000000.0,\n","  \"sliding_window\": null,\n","  \"tie_word_embeddings\": true,\n","  \"torch_dtype\": \"bfloat16\",\n","  \"transformers_version\": \"4.44.2\",\n","  \"use_cache\": true,\n","  \"use_im_start_end\": true,\n","  \"use_sliding_window\": false,\n","  \"vocab_size\": 151860\n","}\n","\n","[INFO:swift] model.generation_config: GenerationConfig {\n","  \"bos_token_id\": 151643,\n","  \"eos_token_id\": 151645,\n","  \"max_new_tokens\": 2048,\n","  \"pad_token_id\": 151643\n","}\n","\n","[INFO:swift] [base_model.model.model.embed_tokens.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n","[INFO:swift] [base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n","[INFO:swift] [base_model.model.model.layers.0.self_attn.q_proj.base_layer.bias]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n","[INFO:swift] [base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n","[INFO:swift] [base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n","[INFO:swift] [base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n","[INFO:swift] [base_model.model.model.layers.0.self_attn.k_proj.base_layer.bias]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n","[INFO:swift] [base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n","[INFO:swift] [base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n","[INFO:swift] [base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n","[INFO:swift] [base_model.model.model.layers.0.self_attn.v_proj.base_layer.bias]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n","[INFO:swift] [base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n","[INFO:swift] [base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n","[INFO:swift] [base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n","[INFO:swift] [base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n","[INFO:swift] [base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n","[INFO:swift] [base_model.model.model.layers.0.mlp.gate_proj.base_layer.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n","[INFO:swift] [base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n","[INFO:swift] [base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n","[INFO:swift] [base_model.model.model.layers.0.mlp.up_proj.base_layer.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n","[INFO:swift] ...\n","[INFO:swift] PeftModelForCausalLM(\n","  (base_model): LoraModel(\n","    (model): GOTQwenForCausalLM(\n","      (model): GOTQwenModel(\n","        (embed_tokens): Embedding(151860, 1024)\n","        (layers): ModuleList(\n","          (0-23): 24 x Qwen2DecoderLayer(\n","            (self_attn): Qwen2SdpaAttention(\n","              (q_proj): lora.Linear(\n","                (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1024, out_features=8, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=8, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (k_proj): lora.Linear(\n","                (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1024, out_features=8, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=8, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (v_proj): lora.Linear(\n","                (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1024, out_features=8, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=8, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (o_proj): lora.Linear(\n","                (base_layer): Linear(in_features=1024, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1024, out_features=8, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=8, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (rotary_emb): Qwen2RotaryEmbedding()\n","            )\n","            (mlp): Qwen2MLP(\n","              (gate_proj): lora.Linear(\n","                (base_layer): Linear(in_features=1024, out_features=2816, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1024, out_features=8, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=8, out_features=2816, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (up_proj): lora.Linear(\n","                (base_layer): Linear(in_features=1024, out_features=2816, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=1024, out_features=8, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=8, out_features=2816, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (down_proj): lora.Linear(\n","                (base_layer): Linear(in_features=2816, out_features=1024, bias=False)\n","                (lora_dropout): ModuleDict(\n","                  (default): Dropout(p=0.05, inplace=False)\n","                )\n","                (lora_A): ModuleDict(\n","                  (default): Linear(in_features=2816, out_features=8, bias=False)\n","                )\n","                (lora_B): ModuleDict(\n","                  (default): Linear(in_features=8, out_features=1024, bias=False)\n","                )\n","                (lora_embedding_A): ParameterDict()\n","                (lora_embedding_B): ParameterDict()\n","                (lora_magnitude_vector): ModuleDict()\n","              )\n","              (act_fn): SiLU()\n","            )\n","            (input_layernorm): Qwen2RMSNorm((1024,), eps=1e-06)\n","            (post_attention_layernorm): Qwen2RMSNorm((1024,), eps=1e-06)\n","          )\n","        )\n","        (norm): Qwen2RMSNorm((1024,), eps=1e-06)\n","        (vision_tower_high): ImageEncoderViT(\n","          (patch_embed): PatchEmbed(\n","            (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n","          )\n","          (blocks): ModuleList(\n","            (0-11): 12 x Block(\n","              (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","              (attn): Attention(\n","                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n","                (proj): Linear(in_features=768, out_features=768, bias=True)\n","              )\n","              (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n","              (mlp): MLPBlock(\n","                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","                (act): GELU(approximate='none')\n","              )\n","            )\n","          )\n","          (neck): Sequential(\n","            (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (1): LayerNorm2d()\n","            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (3): LayerNorm2d()\n","          )\n","          (net_2): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","          (net_3): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        )\n","        (mm_projector_vary): lora.Linear(\n","          (base_layer): Linear(in_features=1024, out_features=1024, bias=True)\n","          (lora_dropout): ModuleDict(\n","            (default): Dropout(p=0.05, inplace=False)\n","          )\n","          (lora_A): ModuleDict(\n","            (default): Linear(in_features=1024, out_features=8, bias=False)\n","          )\n","          (lora_B): ModuleDict(\n","            (default): Linear(in_features=8, out_features=1024, bias=False)\n","          )\n","          (lora_embedding_A): ParameterDict()\n","          (lora_embedding_B): ParameterDict()\n","          (lora_magnitude_vector): ModuleDict()\n","        )\n","      )\n","      (lm_head): Linear(in_features=1024, out_features=151860, bias=False)\n","    )\n","  )\n",")\n","[INFO:swift] PeftModelForCausalLM: 564.3297M Params (0.0000M Trainable [0.0000%]), 100.6641M Buffers.\n","[INFO:swift] system:         You should follow the instructions carefully and explain your answers in detail.\n","Generating train split: 10 examples [00:00, 671.23 examples/s]\n","[INFO:swift] val_dataset: Dataset({\n","    features: ['query', 'response', 'images'],\n","    num_rows: 1\n","})\n","[INFO:swift] Setting args.verbose: True\n","[PROMPT]<|im_start|>system\n","        You should follow the instructions carefully and explain your answers in detail.<|im_end|>\n","<|im_start|>user\n","<img>[151859 * 256]</img>\n","Transcribe the text in this image<|im_end|>\n","<|im_start|>assistant\n","[OUTPUT]The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n","गम ख़कीठ विस्मीवन दोड़ा।<|im_end|>\n","\n","[LABELS]अधिग्रहण पर अधिग्रहण, गूगल का इरादा क्या है\n","[IMAGES]['/kaggle/input/hindi-ocr-synthetic-line-image-text-pair/data_80k/TestSamples/9.png']\n","--------------------------------------------------\n","[INFO:swift] save_result_path: /kaggle/working/hindi_got_model_3/got-ocr2/v0-20240930-060444/checkpoint-1000/infer_result/20240930-081911.jsonl\n","[INFO:swift] End time of running main: 2024-09-30 08:19:13.845718\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0 swift infer\\\n","--ckpt_dir /kaggle/working/hindi_got_model_3/got-ocr2/v0-20240930-060444/checkpoint-1000 \\\n","--dataset /kaggle/working/test1.json \\\n","--load_dataset_config true "]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-09-30T08:22:44.578812Z","iopub.status.busy":"2024-09-30T08:22:44.578255Z","iopub.status.idle":"2024-09-30T08:22:47.861325Z","shell.execute_reply":"2024-09-30T08:22:47.860197Z","shell.execute_reply.started":"2024-09-30T08:22:44.578755Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["  adding: kaggle/working/hindi_got_model_3/got-ocr2/v0-20240930-060444/checkpoint-1000/ (stored 0%)\n","  adding: kaggle/working/hindi_got_model_3/got-ocr2/v0-20240930-060444/checkpoint-1000/adapter_config.json (deflated 47%)\n","  adding: kaggle/working/hindi_got_model_3/got-ocr2/v0-20240930-060444/checkpoint-1000/training_args.bin (deflated 53%)\n","  adding: kaggle/working/hindi_got_model_3/got-ocr2/v0-20240930-060444/checkpoint-1000/infer_result/ (stored 0%)\n","  adding: kaggle/working/hindi_got_model_3/got-ocr2/v0-20240930-060444/checkpoint-1000/infer_result/20240930-081911.jsonl (deflated 31%)\n","  adding: kaggle/working/hindi_got_model_3/got-ocr2/v0-20240930-060444/checkpoint-1000/additional_config.json (deflated 27%)\n","  adding: kaggle/working/hindi_got_model_3/got-ocr2/v0-20240930-060444/checkpoint-1000/configuration.json (deflated 40%)\n","  adding: kaggle/working/hindi_got_model_3/got-ocr2/v0-20240930-060444/checkpoint-1000/trainer_state.json (deflated 81%)\n","  adding: kaggle/working/hindi_got_model_3/got-ocr2/v0-20240930-060444/checkpoint-1000/README.md (deflated 66%)\n","  adding: kaggle/working/hindi_got_model_3/got-ocr2/v0-20240930-060444/checkpoint-1000/optimizer.pt (deflated 7%)\n","  adding: kaggle/working/hindi_got_model_3/got-ocr2/v0-20240930-060444/checkpoint-1000/sft_args.json (deflated 67%)\n","  adding: kaggle/working/hindi_got_model_3/got-ocr2/v0-20240930-060444/checkpoint-1000/generation_config.json (deflated 36%)\n","  adding: kaggle/working/hindi_got_model_3/got-ocr2/v0-20240930-060444/checkpoint-1000/adapter_model.safetensors (deflated 7%)\n","  adding: kaggle/working/hindi_got_model_3/got-ocr2/v0-20240930-060444/checkpoint-1000/rng_state.pth (deflated 25%)\n","  adding: kaggle/working/hindi_got_model_3/got-ocr2/v0-20240930-060444/checkpoint-1000/scheduler.pt (deflated 56%)\n","Zip file created: /kaggle/working/checkpoint-1000.zip\n"]}],"source":["import os\n","\n","# Define the path to the checkpoint\n","checkpoint_path = \"/kaggle/working/hindi_got_model_3/got-ocr2/v0-20240930-060444/checkpoint-1000\"\n","\n","# Create a zip file name\n","zip_name = \"checkpoint-1000.zip\"\n","\n","# Create the zip file\n","!zip -r /kaggle/working/{zip_name} {checkpoint_path}\n","\n","print(f\"Zip file created: /kaggle/working/{zip_name}\")"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4568504,"sourceId":7801974,"sourceType":"datasetVersion"}],"dockerImageVersionId":30776,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
